{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problems\n",
    "### Lecture 24\n",
    "Answer each number in a separate cell\n",
    "\n",
    "Rename the notebook with your lastName and the lecture \n",
    "    \n",
    "    ex. CychB_24\n",
    "    \n",
    "Turn this notebook into triton-ed by the end of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification\n",
    "- Import the tab separated dataset 'Datasets/Forams/Forams.txt' into a pandas dataframe.\n",
    "- This dataset has several variables that describe the morphology of 2 different foram species. These are 'Ø [mm]','Perc [%]' and 'Growth [%]'. Ø is a measure of size that sedimentologists use.  They prefer the use of $\\phi$ instead of grain size.  $\\phi$  which is related to grain size by: \n",
    "\n",
    "$\\phi = -log_2 D$, were $D$ is the grain size in mm.  \n",
    "\n",
    "Here is a helpful guide to understanding sedimentological\n",
    "grain size scales:  \n",
    "\n",
    "$\\phi$ scale | Size range | Wentworth class | Other names\n",
    "------------|-----------|--------------|---------------\n",
    "<−8 | >256 mm | Boulder |\n",
    "−6 to −8 | 64–256 mm | Cobble | \n",
    "−5 to −6 | 32–64 mm | Very coarse gravel | Pebble\n",
    "−4 to −5 | 16–32 mm | Coarse gravel | Pebble\n",
    "−3 to −4 | 8–16 mm | Medium gravel | Pebble\n",
    "−2 to −3 | 4–8 mm | Fine gravel | Pebble\n",
    "−1 to −2 | 2–4 mm | Very fine gravel | Granule  \n",
    "0 to −1 | 1–2 mm | Very coarse sand |   \n",
    "1 to 0 | 0.5–1 mm | Coarse sand | \n",
    "2 to 1 | 0.25–0.5 mm | Medium sand |    \n",
    "3 to 2 | 125–250 µm | Fine sand |       \n",
    "4 to 3 | 62.5–125 µm | Very fine sand | \n",
    "8 to 4 | 3.9–62.5 µm | Silt | Mud\n",
    "10 to 8 | 0.98–3.9 µm | Clay | Mud\n",
    "20 to 10 | 0.95–977 nm | Colloid | Mud\n",
    "\n",
    "\n",
    "\n",
    "Plot the three parameters against one another in a pairplot and color the points by Species.\n",
    "- Randomize the dataset and make the first half into a training dataset.  \n",
    "- Use the scikit-learn algorithm GaussianNB() to create a model for your data.  Here you want to use the Species designations as your training values\n",
    "- Classify the second half of your dataset using the model you made and plot the classified datapoints in a pairplot.\n",
    "- How does this compare with just using the 'Species' to set the hue?  Did the paleontologists do a good job in picking their species?  \n",
    "\n",
    "\n",
    "# 2. PCA\n",
    "- Perform a principal component analysis on original DataFrame to get 2 components. Display your data in the coordinate system of these components using sns.scatterplot. Color by Species.\n",
    "- Use GaussianNB() to classify these data as before, but this time use your PCA_1 to classify. The two PCAs are not independent as the sum to unity, so you can use either one. Based on your pairplot, place forams into one of two clusters:  cluster\\_1, cluster\\_2.  Then use the cluster designation as your Y in **GaussianNB()** \n",
    "- Plot your classified data. Does this do a better job than in part 1? Does this also mean that we don't need paleontologists??  \n",
    "\n",
    "# 3.  K mean Clustering\n",
    "- Use the Scikitlearn KMeans algorithm on your data, using the principal components as your dimensions. \n",
    "- Plot your clustered data. Did the algorithm work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
